Loading data...
Build model...
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 300)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 300, 300)          26729400  
_________________________________________________________________
dropout_1 (Dropout)          (None, 300, 300)          0         
_________________________________________________________________
onlstm_1 (ONLSTM)            (None, 300, 300)          723604    
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 300)               0         
_________________________________________________________________
documentOut_1 (Dense)        (None, 300)               90300     
_________________________________________________________________
dropout2 (Dropout)           (None, 300)               0         
_________________________________________________________________
normal1 (BatchNormalization) (None, 300)               1200      
_________________________________________________________________
output_1 (Dense)             (None, 9)                 2709      
=================================================================
Total params: 27,547,213
Trainable params: 817,213
Non-trainable params: 26,730,000
_________________________________________________________________
Train...
Train on 246802 samples, validate on 27423 samples
Epoch 1/100

    64/246802 [..............................] - ETA: 1:03:53 - loss: 2.7696 - accuracy: 0.1406
   128/246802 [..............................] - ETA: 40:29 - loss: 2.8224 - accuracy: 0.1406  
   192/246802 [..............................] - ETA: 32:25 - loss: 2.8126 - accuracy: 0.1458
   256/246802 [..............................] - ETA: 28:14 - loss: 2.8363 - accuracy: 0.1523
   320/246802 [..............................] - ETA: 25:44 - loss: 2.7689 - accuracy: 0.1469
   384/246802 [..............................] - ETA: 24:08 - loss: 2.7617 - accuracy: 0.1484
   448/246802 [..............................] - ETA: 23:00 - loss: 2.7427 - accuracy: 0.1585
   512/246802 [..............................] - ETA: 22:09 - loss: 2.7115 - accuracy: 0.1699
   576/246802 [..............................] - ETA: 21:24 - loss: 2.6920 - accuracy: 0.1719
   640/246802 [..............................] - ETA: 20:51 - loss: 2.6813 - accuracy: 0.1750
   704/246802 [..............................] - ETA: 20:23 - loss: 2.6513 - accuracy: 0.1761
   768/246802 [..............................] - ETA: 20:01 - loss: 2.6261 - accuracy: 0.1849
   832/246802 [..............................] - ETA: 19:43 - loss: 2.5963 - accuracy: 0.1875
   896/246802 [..............................] - ETA: 19:24 - loss: 2.5794 - accuracy: 0.1964
   960/246802 [..............................] - ETA: 19:10 - loss: 2.5472 - accuracy: 0.2083
  1024/246802 [..............................] - ETA: 18:56 - loss: 2.5099 - accuracy: 0.2158
  1088/246802 [..............................] - ETA: 18:42 - loss: 2.4714 - accuracy: 0.2252
  1152/246802 [..............................] - ETA: 18:30 - loss: 2.4352 - accuracy: 0.2326
  1216/246802 [..............................] - ETA: 18:23 - loss: 2.3986 - accuracy: 0.2426
  1280/246802 [..............................] - ETA: 18:14 - loss: 2.3718 - accuracy: 0.2461
  1344/246802 [..............................] - ETA: 18:05 - loss: 2.3357 - accuracy: 0.2597
  1408/246802 [..............................] - ETA: 17:59 - loss: 2.3010 - accuracy: 0.2706
  1472/246802 [..............................] - ETA: 17:54 - loss: 2.2584 - accuracy: 0.2833
  1536/246802 [..............................] - ETA: 17:48 - loss: 2.2176 - accuracy: 0.2962
  1600/246802 [..............................] - ETA: 17:41 - loss: 2.1886 - accuracy: 0.3050
  1664/246802 [..............................] - ETA: 17:38 - loss: 2.1651 - accuracy: 0.3149
  1728/246802 [..............................] - ETA: 17:33 - loss: 2.1335 - accuracy: 0.3241
  1792/246802 [..............................] - ETA: 17:28 - loss: 2.1147 - accuracy: 0.3309
  1856/246802 [..............................] - ETA: 17:26 - loss: 2.0950 - accuracy: 0.3394
  1920/246802 [..............................] - ETA: 17:21 - loss: 2.0722 - accuracy: 0.3479
  1984/246802 [..............................] - ETA: 17:17 - loss: 2.0460 - accuracy: 0.3553
  2048/246802 [..............................] - ETA: 17:13 - loss: 2.0352 - accuracy: 0.3604
  2112/246802 [..............................] - ETA: 17:09 - loss: 2.0193 - accuracy: 0.3670
  2176/246802 [..............................] - ETA: 17:08 - loss: 1.9902 - accuracy: 0.3759
  2240/246802 [..............................] - ETA: 17:04 - loss: 1.9731 - accuracy: 0.3826
  2304/246802 [..............................] - ETA: 17:01 - loss: 1.9436 - accuracy: 0.3911
  2368/246802 [..............................] - ETA: 16:58 - loss: 1.9246 - accuracy: 0.3970
  2432/246802 [..............................] - ETA: 16:55 - loss: 1.9154 - accuracy: 0.4034
  2496/246802 [..............................] - ETA: 16:53 - loss: 1.8945 - accuracy: 0.4111
  2560/246802 [..............................] - ETA: 16:50 - loss: 1.8716 - accuracy: 0.4184
  2624/246802 [..............................] - ETA: 16:47 - loss: 1.8429 - accuracy: 0.4264
  2688/246802 [..............................] - ETA: 16:47 - loss: 1.8183 - accuracy: 0.4345
  2752/246802 [..............................] - ETA: 16:45 - loss: 1.7919 - accuracy: 0.4430
  2816/246802 [..............................] - ETA: 16:44 - loss: 1.7689 - accuracy: 0.4503
  2880/246802 [..............................] - ETA: 16:43 - loss: 1.7558 - accuracy: 0.4552
  2944/246802 [..............................] - ETA: 16:41 - loss: 1.7376 - accuracy: 0.4613
  3008/246802 [..............................] - ETA: 16:40 - loss: 1.7221 - accuracy: 0.4661
  3072/246802 [..............................] - ETA: 16:38 - loss: 1.6963 - accuracy: 0.4749
  3136/246802 [..............................] - ETA: 16:37 - loss: 1.6728 - accuracy: 0.4828
  3200/246802 [..............................] - ETA: 16:35 - loss: 1.6585 - accuracy: 0.4875
  3264/246802 [..............................] - ETA: 16:34 - loss: 1.6447 - accuracy: 0.4926
  3328/246802 [..............................] - ETA: 16:32 - loss: 1.6287 - accuracy: 0.4979
  3392/246802 [..............................] - ETA: 16:31 - loss: 1.6087 - accuracy: 0.5044
  3456/246802 [..............................] - ETA: 16:30 - loss: 1.5900 - accuracy: 0.5104
  3520/246802 [..............................] - ETA: 16:29 - loss: 1.5758 - accuracy: 0.5153
  3584/246802 [..............................] - ETA: 16:27 - loss: 1.5623 - accuracy: 0.5190
  3648/246802 [..............................] - ETA: 16:26 - loss: 1.5445 - accuracy: 0.5244
  3712/246802 [..............................] - ETA: 16:24 - loss: 1.5273 - accuracy: 0.5302
  3776/246802 [..............................] - ETA: 16:22 - loss: 1.5113 - accuracy: 0.5358
  3840/246802 [..............................] - ETA: 16:22 - loss: 1.4988 - accuracy: 0.5404
  3904/246802 [..............................] - ETA: 16:21 - loss: 1.4839 - accuracy: 0.5453
  3968/246802 [..............................] - ETA: 16:19 - loss: 1.4728 - accuracy: 0.5489
  4032/246802 [..............................] - ETA: 16:18 - loss: 1.4617 - accuracy: 0.5521